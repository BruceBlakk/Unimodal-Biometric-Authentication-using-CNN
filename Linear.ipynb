{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a10b7710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #linear algebra\n",
    "import cv2\n",
    "import pandas as pd # this is for inmporting files\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt #ths is for graphing and presentation\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "#rom tflearn.layers.core import input_data, dropout, fully_connected\n",
    "#from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce6a77",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ce05c",
   "metadata": {},
   "source": [
    "#### Getting the image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3051206a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-26fd45570830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnew_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "#file = r\"C:\\Users\\vhlungwane\\Desktop\\ACML project\\Dataset\"\n",
    "file = \"/home/vmuser/Desktop/Dataset\"\n",
    "Cat = [\"Brad Pitt\",\"Alia Bhatt\",\"Anushka Sharma\",\"Amitabh Bachchan\",\"Andy Samberg\",\"Alexandra Daddario\",\"Brad Pitt\",\"Ellen Degeneres\",\"Hugh Jackman\",\"Jessica Alba\"]\n",
    "#\"Alia Bhatt\"\"Amitabh Bachchan\"\n",
    "for category in Cat:\n",
    "    data = []\n",
    "    path = os.path.join(file, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        new_array = cv2.resize(img_array, (50,50))\n",
    "        data.append([np.array(new_array), labels(category)])\n",
    "        print(data)\n",
    "        plt.imshow(new_array, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc736cf9",
   "metadata": {},
   "source": [
    "### Making the labels(One-hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c1239",
   "metadata": {},
   "source": [
    "#### This is the enrollment stage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "233e29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(image_name):\n",
    "    name = image_name\n",
    "    if name == \"Akshay Kumar\":\n",
    "        return np.array([1,0,0,0,0,0,0,0,0,0])\n",
    "    elif name == \"Alexandra Daddario\":\n",
    "        return np.array([0,1,0,0,0,0,0,0,0,0])\n",
    "    elif name == \"Alia Bhatt\":\n",
    "        return np.array([0,0,1,0,0,0,0,0,0,0])\n",
    "    elif name == \"Amitabh Bachchan\":\n",
    "        return np.array([0,0,0,1,0,0,0,0,0,0])\n",
    "    elif name == \"Andy Samberg\":\n",
    "        return np.array([0,0,0,0,1,0,0,0,0,0])\n",
    "    elif name == \"Anushka Sharma\":\n",
    "        return np.array([0,0,0,0,0,1,0,0,0,0])\n",
    "    elif name == \"Brad Pitt\":\n",
    "        return np.array([0,0,0,0,0,0,1,0,0,0])\n",
    "    elif name == \"Ellen Degeneres\":\n",
    "        return np.array([0,0,0,0,0,0,0,1,0,0])\n",
    "    elif name == \"Hugh Jackman\":\n",
    "        return np.array([0,0,0,0,0,0,0,0,1,0])\n",
    "    elif name == \"Jessica Alba\":\n",
    "        return np.array([0,0,0,0,0,0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278169c",
   "metadata": {},
   "source": [
    "### Storing the image data into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cd80385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features():\n",
    "    data = []\n",
    "    for category in Cat:\n",
    "        path = os.path.join(file, category)\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "            new_array = cv2.resize(img_array, (50,50))\n",
    "            data.append([np.array(new_array), labels(category)])\n",
    "            #plt.imshow(new_array, cmap=\"gray\")\n",
    "            #plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49821456",
   "metadata": {},
   "source": [
    "#### Checking the size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e49a7bae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fddee9d",
   "metadata": {},
   "source": [
    "#### Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15c4ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.shuffle(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75daa334",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([data[i][0] for i in range(len(data))])\n",
    "labels = np.array([data[i][1] for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e63e135",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7843006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_S = np.split(image,[300, 400])\n",
    "labels_S = np.split(labels,[300, 400])\n",
    "\n",
    "X_train = image_S[0]\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "X_test = image_S[1]\n",
    "X_test = tf.expand_dims(X_test, axis=-1)\n",
    "X_validate = image_S[1]\n",
    "X_validate = tf.expand_dims(X_validate, axis=-1)\n",
    "\n",
    "\n",
    "Y_train = labels_S[0]\n",
    "Y_test = labels_S[1]\n",
    "Y_validate = labels_S[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df2b348",
   "metadata": {},
   "source": [
    "### Dimesions of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0dc9166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 50, 50, 1)\n",
      "(100, 50, 50, 1)\n",
      "(100, 50, 50, 1)\n",
      "(300, 10)\n",
      "(100, 10)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validate.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e33bdd8",
   "metadata": {},
   "source": [
    "#### Presenting a sample from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2cd43d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample from the feature data\n",
      "[[21 22 30 ... 85 83 78]\n",
      " [38 37 43 ... 83 77 69]\n",
      " [28 30 36 ... 85 85 82]\n",
      " ...\n",
      " [60 56 51 ... 70 53 29]\n",
      " [58 48 41 ... 70 53 30]\n",
      " [56 47 37 ... 68 49 24]]\n",
      "This is the corresponding sample from the label data\n",
      "[0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for  i in data[:1]:\n",
    "    print(\"This is a sample from the feature data\")\n",
    "    print(i[0])\n",
    "    print(\"This is the corresponding sample from the label data\")\n",
    "    print(i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fda13",
   "metadata": {},
   "source": [
    "#### Spliting the training data from the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa69576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Plot_Training_Progress(history):\n",
    "#     acc = history['accuracy']\n",
    "#     val_acc = history['val_accuracy']\n",
    "#     loss = history['loss']\n",
    "#     val_loss = history['val_loss']\n",
    "#     epochs = range(len(acc))\n",
    "\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(25,10))\n",
    "    \n",
    "#     #Plot Accuracy\n",
    "#     axes[0].plot(epochs, acc, 'b-', label='Training Accuracy')\n",
    "#     axes[0].plot(epochs, val_acc, 'g--', label='Validation Accuracy')\n",
    "#     axes[0].set_title('Training and Validation Accuracy')\n",
    "#     axes[0].set_xlabel('Epoch')\n",
    "#     axes[0].set_ylabel('Accuracy')\n",
    "#     axes[0].legend(loc='best')\n",
    "\n",
    "#     #Plot Loss\n",
    "#     axes[1].plot(epochs, loss, 'b-', label='Training Loss')\n",
    "#     axes[1].plot(epochs, val_loss, 'g--', label='Validation Loss')\n",
    "#     axes[1].set_title('Training and Validation Loss')\n",
    "#     axes[1].set_xlabel('Epoch')\n",
    "#     axes[1].set_ylabel('Loss')\n",
    "#     axes[1].legend(loc='best')\n",
    "\n",
    "#     return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d4dbaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X_train):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "084ba0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = normalize_features(X_train)\n",
    "#X_test = normalize_features(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650131f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "793c49b9",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c2b28",
   "metadata": {},
   "source": [
    "#### Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecaca7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "import pydot\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import RandomSearch ,Hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8bd5b6",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "def9c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32,3,data_format='channels_last',activation='relu',input_shape=(50,50,1)))\n",
    "#model.add(Convolution2D(32,3,data_format='channels_last',activation='relu',input_shape=(50,50,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "#model.add(Convolution2D(32,3,data_format='channels_last',activation='relu',input_shape=(50,50,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2000))\n",
    "model.add(Dense(3000))\n",
    "model.add(Dense(40000))\n",
    "#model.add(Dense(5000))\n",
    "#model.add(Dense(6000))\n",
    "model.add(Dropout(0.8))\n",
    "#model.add(Convolution2D(10,3,data_format='channels_last',activation='relu',input_shape=(50,50,1)))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00b63eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2000)              5186000   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3000)              6003000   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 40000)             120040000 \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                400010    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 131,629,330\n",
      "Trainable params: 131,629,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a327151d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, to_file='Baseline_Model_Architecture.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0aef10",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1e30dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 46.3005 - accuracy: 0.1252 - val_loss: 24.2724 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 43.8317 - accuracy: 0.1366 - val_loss: 9.5906 - val_accuracy: 0.2000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 42.4673 - accuracy: 0.1178 - val_loss: 13.7078 - val_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 36.4322 - accuracy: 0.1533 - val_loss: 14.6277 - val_accuracy: 0.2100\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 46.3808 - accuracy: 0.1158 - val_loss: 8.3176 - val_accuracy: 0.2600\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 39.0704 - accuracy: 0.1957 - val_loss: 7.0508 - val_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 40.2493 - accuracy: 0.1148 - val_loss: 9.2511 - val_accuracy: 0.2100\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 64ms/step - loss: 39.0700 - accuracy: 0.1356 - val_loss: 12.8051 - val_accuracy: 0.2300\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 66ms/step - loss: 38.7459 - accuracy: 0.1995 - val_loss: 7.1765 - val_accuracy: 0.3300\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 36.6809 - accuracy: 0.1947 - val_loss: 5.8875 - val_accuracy: 0.3400\n"
     ]
    }
   ],
   "source": [
    "Baseline_History = model.fit(X_train,Y_train,epochs = 10,validation_data=(X_validate,Y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bea13fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = Plot_Training_Progress(Baseline_History.history)   \n",
    "# plt.savefig('Baseline_Plots.png', dpi=400)    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c495eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 5.8875 - accuracy: 0.3400\n",
      "Testing Loss 5.887545108795166\n",
      "Testing Accuracy 34.00%\n"
     ]
    }
   ],
   "source": [
    "testLoss, testAccuracy = model.evaluate(X_test,Y_test)\n",
    "\n",
    "print(\"Testing Loss\", testLoss)\n",
    "print(\"Testing Accuracy\", \"{:.2%}\" .format(testAccuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "44a629c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face_hypermodel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(Convolution2D(filters=hp.Choice('Conv_Filters_1',values=[16, 32, 64],default=16),activation='relu',kernel_size=3, input_shape=self.input_shape))\n",
    "        model.add(Convolution2D(filters=hp.Choice('Conv_Filters_2',values=[16, 32, 64],default=16), activation=hp.Choice('Conv_Activation_2',values=['relu', 'sigmoid'],default='relu'),kernel_size=3))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float('Dropout_Rate_1',min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n",
    "\n",
    "        model.add(Convolution2D(filters=hp.Choice('Conv_Filters_3',values=[32, 64, 128],default=32), activation=hp.Choice('Conv_Activation_3',values=['relu', 'sigmoid'],default='relu'),kernel_size=3))\n",
    "        model.add(Convolution2D(filters=hp.Choice('Conv_Filters_4',values=[32, 64, 128],default=64), activation=hp.Choice('Conv_Activation_4',values=['relu', 'sigmoid'],default='relu'),kernel_size=3))\n",
    "        model.add(AveragePooling2D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float('Dropout_Rate_2',min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('Last_Dense_NumUnits',min_value=16,max_value=128,step=16,default=64), activation='relu'))\n",
    "        model.add(Dropout(rate=hp.Float('Dropout_Rate_3',min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=keras.optimizers.Adam(hp.Float('Adam_Optim_LR',min_value=1e-4,max_value=1e-2,sampling='LOG',default=1e-3)),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        print(\"MODEL SUCCESSFULLY CREATED\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9821437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hyper_model = Face_hypermodel((50,50,1), 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f067cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./Face_HyperTuned/oracle.json\n",
      "MODEL SUCCESSFULLY CREATED\n",
      "INFO:tensorflow:Reloading Tuner from ./Face_HyperTuned/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "maxTrials = 20\n",
    "execPerTrial = 2\n",
    "numEpochSearch = 10\n",
    "seedValue = 2\n",
    "\n",
    "model_tuner = RandomSearch(\n",
    "    hyper_model,\n",
    "    objective='val_accuracy',\n",
    "    seed=seedValue,\n",
    "    max_trials=maxTrials,\n",
    "    executions_per_trial=execPerTrial,\n",
    "    project_name='Face_HyperTuned'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceab4a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "model_tuner.search(x=X_train, y=Y_train, epochs=numEpochSearch, validation_data=(X_validate, Y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ccff2a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./Face_HyperTuned\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fb9ef744580>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 16\n",
      "Conv_Filters_2: 16\n",
      "Conv_Activation_2: sigmoid\n",
      "Dropout_Rate_1: 0.25\n",
      "Conv_Filters_3: 32\n",
      "Conv_Activation_3: relu\n",
      "Conv_Filters_4: 128\n",
      "Conv_Activation_4: relu\n",
      "Dropout_Rate_2: 0.5\n",
      "Last_Dense_NumUnits: 112\n",
      "Dropout_Rate_3: 0.35000000000000003\n",
      "Adam_Optim_LR: 0.0005674460859990781\n",
      "Score: 0.4599999934434891\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 64\n",
      "Conv_Filters_2: 32\n",
      "Conv_Activation_2: sigmoid\n",
      "Dropout_Rate_1: 0.2\n",
      "Conv_Filters_3: 32\n",
      "Conv_Activation_3: relu\n",
      "Conv_Filters_4: 128\n",
      "Conv_Activation_4: relu\n",
      "Dropout_Rate_2: 0.45\n",
      "Last_Dense_NumUnits: 48\n",
      "Dropout_Rate_3: 0.05\n",
      "Adam_Optim_LR: 0.00036276965095376624\n",
      "Score: 0.39000000059604645\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 32\n",
      "Conv_Filters_2: 64\n",
      "Conv_Activation_2: relu\n",
      "Dropout_Rate_1: 0.1\n",
      "Conv_Filters_3: 32\n",
      "Conv_Activation_3: sigmoid\n",
      "Conv_Filters_4: 32\n",
      "Conv_Activation_4: relu\n",
      "Dropout_Rate_2: 0.25\n",
      "Last_Dense_NumUnits: 64\n",
      "Dropout_Rate_3: 0.45\n",
      "Adam_Optim_LR: 0.0011418581028573094\n",
      "Score: 0.32500000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 32\n",
      "Conv_Filters_2: 16\n",
      "Conv_Activation_2: sigmoid\n",
      "Dropout_Rate_1: 0.30000000000000004\n",
      "Conv_Filters_3: 32\n",
      "Conv_Activation_3: relu\n",
      "Conv_Filters_4: 128\n",
      "Conv_Activation_4: relu\n",
      "Dropout_Rate_2: 0.30000000000000004\n",
      "Last_Dense_NumUnits: 48\n",
      "Dropout_Rate_3: 0.15000000000000002\n",
      "Adam_Optim_LR: 0.0009749332269823054\n",
      "Score: 0.32500000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 32\n",
      "Conv_Filters_2: 64\n",
      "Conv_Activation_2: sigmoid\n",
      "Dropout_Rate_1: 0.15000000000000002\n",
      "Conv_Filters_3: 32\n",
      "Conv_Activation_3: sigmoid\n",
      "Conv_Filters_4: 32\n",
      "Conv_Activation_4: relu\n",
      "Dropout_Rate_2: 0.45\n",
      "Last_Dense_NumUnits: 112\n",
      "Dropout_Rate_3: 0.05\n",
      "Adam_Optim_LR: 0.0014517231809036133\n",
      "Score: 0.22499999403953552\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 16\n",
      "Conv_Filters_2: 16\n",
      "Conv_Activation_2: relu\n",
      "Dropout_Rate_1: 0.30000000000000004\n",
      "Conv_Filters_3: 128\n",
      "Conv_Activation_3: sigmoid\n",
      "Conv_Filters_4: 32\n",
      "Conv_Activation_4: sigmoid\n",
      "Dropout_Rate_2: 0.30000000000000004\n",
      "Last_Dense_NumUnits: 64\n",
      "Dropout_Rate_3: 0.25\n",
      "Adam_Optim_LR: 0.00032962260207930136\n",
      "Score: 0.2199999988079071\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 32\n",
      "Conv_Filters_2: 16\n",
      "Conv_Activation_2: sigmoid\n",
      "Dropout_Rate_1: 0.0\n",
      "Conv_Filters_3: 32\n",
      "Conv_Activation_3: sigmoid\n",
      "Conv_Filters_4: 128\n",
      "Conv_Activation_4: relu\n",
      "Dropout_Rate_2: 0.35000000000000003\n",
      "Last_Dense_NumUnits: 112\n",
      "Dropout_Rate_3: 0.25\n",
      "Adam_Optim_LR: 0.00014948684422968163\n",
      "Score: 0.2149999961256981\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 64\n",
      "Conv_Filters_2: 32\n",
      "Conv_Activation_2: relu\n",
      "Dropout_Rate_1: 0.25\n",
      "Conv_Filters_3: 32\n",
      "Conv_Activation_3: sigmoid\n",
      "Conv_Filters_4: 32\n",
      "Conv_Activation_4: relu\n",
      "Dropout_Rate_2: 0.1\n",
      "Last_Dense_NumUnits: 48\n",
      "Dropout_Rate_3: 0.35000000000000003\n",
      "Adam_Optim_LR: 0.0003243806953412315\n",
      "Score: 0.21000000089406967\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 64\n",
      "Conv_Filters_2: 64\n",
      "Conv_Activation_2: relu\n",
      "Dropout_Rate_1: 0.25\n",
      "Conv_Filters_3: 128\n",
      "Conv_Activation_3: relu\n",
      "Conv_Filters_4: 32\n",
      "Conv_Activation_4: relu\n",
      "Dropout_Rate_2: 0.25\n",
      "Last_Dense_NumUnits: 80\n",
      "Dropout_Rate_3: 0.15000000000000002\n",
      "Adam_Optim_LR: 0.002312113349326375\n",
      "Score: 0.1899999976158142\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv_Filters_1: 32\n",
      "Conv_Filters_2: 16\n",
      "Conv_Activation_2: sigmoid\n",
      "Dropout_Rate_1: 0.45\n",
      "Conv_Filters_3: 64\n",
      "Conv_Activation_3: sigmoid\n",
      "Conv_Filters_4: 128\n",
      "Conv_Activation_4: sigmoid\n",
      "Dropout_Rate_2: 0.05\n",
      "Last_Dense_NumUnits: 96\n",
      "Dropout_Rate_3: 0.2\n",
      "Adam_Optim_LR: 0.0013291852527485804\n",
      "Score: 0.1899999976158142\n"
     ]
    }
   ],
   "source": [
    "model_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d954e",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "751c0434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43cd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce362c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd649734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fc9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87319b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d7a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c2734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d597ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f47256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792504eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0463588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264a093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
